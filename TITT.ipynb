{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q80z3tYQ-v-N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPWmZEXbCzRw"
   },
   "source": [
    "## Hyperparameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ziG6hh4Cyuv"
   },
   "outputs": [],
   "source": [
    "NOISE = 2\n",
    "MEAN_NOISE = 0.0\n",
    "\n",
    "######################################################\n",
    "# fix me\n",
    "# Parameters for CNNs\n",
    "CNN1_inputchannel = 3\n",
    "CNN1_outchannel = 4 \n",
    "CNN1_kernal = 11\n",
    "CNN1_stride = 1\n",
    "\n",
    "CNN2_outchannel = 8\n",
    "CNN2_kernal = 8\n",
    "CNN2_stride = 1\n",
    "\n",
    "CNN3_outchannel = 16\n",
    "CNN3_kernal = 4\n",
    "CNN3_stride = 1\n",
    "\n",
    "Pool_kernal = 2 # max pooling\n",
    "Pool_stride = 2\n",
    "\n",
    "num_epochs = 30\n",
    "batch_size = 15\n",
    "\n",
    "sensor_ref = [0,0]\n",
    "sensor1 = [10,0]\n",
    "sensor2 = [0,10]\n",
    "sensor3 = [10,10]\n",
    "\n",
    "world_size_x = 10\n",
    "world_size_y = 10\n",
    "grid_size = 0.1\n",
    "\n",
    "epsilon = 0.05\n",
    "######################################################\n",
    "\n",
    "MC_N = 10** 4  # Number of total simulation\n",
    "MC_N = int(MC_N * 2)\n",
    "size_x = 10   # X axis size\n",
    "size_y = 10   # Y axis size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaX3b-Sf-7sV"
   },
   "outputs": [],
   "source": [
    "def target_moving(x_cor_list, y_cor_list, velocity_list, acceleration_list): #측정 시간 단위는 1초로! 속도 단위는 m/s\n",
    "    x_cor_t_n_1 = x_cor_list[-1]\n",
    "    y_cor_t_n_1 = y_cor_list[-1]\n",
    "    velocity = velocity_list[-1]\n",
    "    acceleration = acceleration_list[-1]\n",
    "    \n",
    "    s = velocity * 1        \n",
    "    direction = 360 * np.random.rand(1)\n",
    "    \n",
    "    x_cor_t_n = x_cor_t_n_1 + s * math.cos(direction)\n",
    "    y_cor_t_n = y_cor_t_n_1 + s * math.sin(direction)\n",
    "    \n",
    "    if(x_cor_t_n > world_size_x or x_cor_t_n < 0):\n",
    "        x_cor_t_n = x_cor_t_n - 2 * s * math.cos(direction)\n",
    "        \n",
    "    if(y_cor_t_n > world_size_y or y_cor_t_n < 0):\n",
    "        y_cor_t_n = y_cor_t_n - 2 * s * math.sin(direction)\n",
    "        \n",
    "    \n",
    "    x_cor_list.append(round(x_cor_t_n,2))\n",
    "    y_cor_list.append(round(y_cor_t_n,2))   \n",
    "    \n",
    "    acceleration = 0.5 * float(np.random.randn(1))\n",
    "    velocity = velocity + acceleration * 1\n",
    "    \n",
    "    if(velocity < 0):\n",
    "        velocity = 0\n",
    "        \n",
    "    elif(velocity>5): #인간 평균 걸음 속도는 1.1m/s 이고 뛰는 평균 속도는 5m/s이다\n",
    "        velocity = 1.1\n",
    "    \n",
    "    acceleration_list.append(round(acceleration,2))\n",
    "    velocity_list.append(round(velocity,2))\n",
    "    \n",
    "# 타겟 X(대문자 X) , x좌표 x(소문자 x)    \n",
    "X_x_list = [world_size_x / 2]    # 타겟의 첫 x좌표\n",
    "X_y_list = [world_size_y / 2]    # 타겟의 첫 y좌표 \n",
    "velocity_list = [1.1]\n",
    "acceleration_list =[0]   \n",
    "\n",
    "\n",
    "while(len(X_x_list) < MC_N):\n",
    "    target_moving(X_x_list, X_y_list, velocity_list, acceleration_list)\n",
    "\n",
    "\n",
    "sensor_ref_x_list = [0] * MC_N                      #sensor ref x coordinate\n",
    "sensor_ref_y_list = [0] * MC_N                      #sensor ref  y coordinate\n",
    "sensor_one_x_list = [size_x] * MC_N                 #sensor 1 x coordinate\n",
    "sensor_one_y_list = [0] * MC_N                      #sensor 1 y coordinate\n",
    "sensor_two_x_list = [0] * MC_N                      #sensor 2 x coordinate\n",
    "sensor_two_y_list = [size_y] * MC_N                 #sensor 2 y coordinate\n",
    "sensor_three_x_list = [size_x] * MC_N                #sensor 3 x coordinate\n",
    "sensor_three_y_list = [size_y] * MC_N                #sensor 3 y coordinate\n",
    "\n",
    "df = pd.DataFrame(data = {'X_x':X_x_list , 'X_y' : X_y_list  \n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(X_x_list , X_y_list, cmap = \"Blues\" , shade= True, shade_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(X_x_list, X_y_list, kind=\"hex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w9cgueum8no"
   },
   "source": [
    "### Example of a TDOA dataset created through an actual experiment.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1Wym8DdqfQuY4VSDFmxiogRXUl_ade25X' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8jAI_M8_Uoh"
   },
   "source": [
    "### Create distance between each sensor and hat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nv0LR3zY_dAV"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from multilateration_tdoa import TDoAEngine, TDoAMeasurement, Anchor, Point\n",
    "import numpy as np\n",
    "\n",
    "def noise():\n",
    "    \"\"\"Returns gaussian noise\"\"\"\n",
    "    return np.random.normal(MEAN_NOISE, NOISE)\n",
    "\n",
    "def tdoa(A,B,P):\n",
    "    \"\"\"Computes |PB| - |PA| + gaussian noise\"\"\"\n",
    "    return P.dist(B)-P.dist(A) + noise()\n",
    "\n",
    "def fakeTDOA(A,B,P):\n",
    "    \"\"\"Returns a fake measurements with anchors A, B from a point P\"\"\"\n",
    "    return TDoAMeasurement(A, B, tdoa(A,B,P))\n",
    "\n",
    "engine = TDoAEngine(n_measurements=6, max_dist_hess=100) # Avoid value rejection.\n",
    "\n",
    "A = Anchor((0,0,0))\n",
    "B = Anchor((world_size_x,0,0))\n",
    "C = Anchor((world_size_x,world_size_y,0))\n",
    "D = Anchor((0,world_size_y,0))\n",
    "\n",
    "TDOA_X_hat_ref_one_error_list = [-100] * MC_N  \n",
    "TDOA_X_hat_ref_two_error_list = [-100] * MC_N  \n",
    "TDOA_X_hat_ref_three_error_list = [-100] * MC_N  \n",
    " \n",
    "\n",
    "for i in range(MC_N):\n",
    "    P = Point(X_x_list[i],X_y_list[i],0)\n",
    "    \n",
    "    TDOA_X_hat_ref_one_error_list[i] =   float(fakeTDOA(A, B, P).tdoa) # ref과 앵커 B와 TDOA\n",
    "    TDOA_X_hat_ref_two_error_list[i] =  float(fakeTDOA(A, C, P).tdoa) # ref과 앵커 C와 TDOA\n",
    "    TDOA_X_hat_ref_three_error_list[i] =   float(fakeTDOA(A, D, P).tdoa)# ref과 앵커 D와 TDOA\n",
    "\n",
    "df['TDOA_X_hat_ref_one_error'] = TDOA_X_hat_ref_one_error_list\n",
    "df['TDOA_X_hat_ref_two_error'] = TDOA_X_hat_ref_two_error_list\n",
    "df['TDOA_X_hat_ref_three_error'] = TDOA_X_hat_ref_three_error_list\n",
    "\n",
    "df_parsing = df[['TDOA_X_hat_ref_one_error' , 'TDOA_X_hat_ref_two_error' , 'TDOA_X_hat_ref_three_error' , 'X_x' , 'X_y']]\n",
    "df_parsing.columns = ['TDOA_1', 'TDOA_2', 'TDOA_3' , 'coordinate_x' , 'coordinate_y']\n",
    "\n",
    "df_parsing = df_parsing.reset_index(drop=True)\n",
    "\n",
    "TDOA_X_ref_one_list = df_parsing['TDOA_1'].tolist()\n",
    "TDOA_X_ref_two_list = df_parsing['TDOA_2'].tolist()\n",
    "TDOA_X_ref_three_list = df_parsing['TDOA_3'].tolist()\n",
    "\n",
    "TDOA_pair_ref = [(TDOA_X_ref_one_list[ii], TDOA_X_ref_two_list[ii], TDOA_X_ref_three_list[ii]) for ii in range(len(TDOA_X_ref_one_list))]\n",
    "\n",
    "ylabel_ref = [(X_x_list[ii] / size_x, X_y_list[ii] / size_y ) for ii in range(len(X_x_list))] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5f0hP0FA7ru"
   },
   "source": [
    "### Scaling for data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8XC0eLi71dE"
   },
   "outputs": [],
   "source": [
    "def ScalerCoordinate(value):   #world size = area's width and height , value =  x,y coordinate\n",
    "    world_size = 10\n",
    "    value = value / world_size\n",
    "    return value\n",
    "\n",
    "\n",
    "def ScalerTDOA(value):   #world size = area's width and height , value = TDOA value\n",
    "    #world_size = 25 * 2**(0.5)\n",
    "    world_size = 100  \n",
    "    value = value / world_size\n",
    "    return value\n",
    "\n",
    "\n",
    "df = df_parsing\n",
    "\n",
    "df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']] = df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']].apply(ScalerTDOA)  #길이에 대하여 스케일링\n",
    "df[['coordinate_x' , 'coordinate_y']] = df[['coordinate_x' , 'coordinate_y']].apply(ScalerCoordinate)  #좌표에 대하여 스케일링\n",
    "\n",
    "train_df , test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "train_TDOAs = train_df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']].to_numpy()\n",
    "train_X_Hats = train_df[['coordinate_x' , 'coordinate_y']].to_numpy()\n",
    "\n",
    "test_TDOAs = test_df[['TDOA_1' , 'TDOA_2' , 'TDOA_3']].to_numpy()\n",
    "test_X_Hats = test_df[['coordinate_x' , 'coordinate_y']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqb-2NArCTOb"
   },
   "outputs": [],
   "source": [
    "# TDOA image 생성 모듈 정의\n",
    "# input: TDPA\n",
    "# output: TDOA_images\n",
    "\n",
    "def titt(e,epsilon):\n",
    "      if e < epsilon:\n",
    "            return 1\n",
    "      else:\n",
    "            return 0\n",
    "   \n",
    "  \n",
    "def TDOA_image_generation(sensor1, sensor2, TDOA, world_size_x, world_size_y, grid_size, epsilon):\n",
    "   \n",
    "  center_x = np.linspace(0 , world_size_x , int(world_size_x / grid_size))  + 0.5*grid_size  # x길이 10에 그리드사이즈가 2로 가정했을때 해당 좌표의 중심 좌표는 1, 3, 5, 7, 9 => 이를 수학적으로 수열화 한거!\n",
    "  center_y = np.linspace(world_size_y , 0 , int(world_size_x / grid_size))  + 0.5*grid_size  # 마찬가지\n",
    "  cord_center_x, cord_center_y = np.meshgrid(center_x,center_y)  #이를 매트릭스화\n",
    "  \n",
    "  distance_matrix = np.sqrt((cord_center_x - sensor1[0])**2 + (cord_center_y - sensor1[1])**2) - np.sqrt((cord_center_x - sensor2[0])**2 + (cord_center_y - sensor2[1])**2)  # 그리드 사이즈 중심좌표로부터 센서간의 거리의 계산 차 (=중심 좌표의 TDOA)\n",
    "  tdoa_distance = np.abs(distance_matrix - TDOA)  #실제 TDOA 값과 차이 계산\n",
    "\n",
    "  # 예시 [[10.8,0.38]\n",
    "  #        [7.679,12.6479]]\n",
    "  \n",
    "  vfunc = np.vectorize(titt)\n",
    "  tdoa_image = vfunc(tdoa_distance, epsilon)\n",
    "  return tdoa_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yu41V4pfE1ml"
   },
   "source": [
    "  #### Image size\n",
    "\n",
    "- Since Grid_size is 0.25, image size is 100,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "157CHVzI-Eke",
    "outputId": "77c178cd-515e-4064-eade-9797a3b1b0c7"
   },
   "outputs": [],
   "source": [
    "TDOA_sample = TDOA_pair_ref[0][0]\n",
    "TDOA_sample_image = TDOA_image_generation(sensor_ref, sensor1, TDOA_sample, world_size_x, world_size_y, grid_size, epsilon)\n",
    "TDOA_sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDOA_images_ref = []\n",
    "for ii in range(len(TDOA_pair_ref)):\n",
    "    image1 = TDOA_image_generation(sensor_ref, sensor1, TDOA_pair_ref[ii][0], world_size_x, world_size_y, grid_size, epsilon)\n",
    "    image2 = TDOA_image_generation(sensor_ref, sensor2, TDOA_pair_ref[ii][1], world_size_x, world_size_y, grid_size, epsilon)\n",
    "    image3 = TDOA_image_generation(sensor_ref, sensor3, TDOA_pair_ref[ii][2], world_size_x, world_size_y, grid_size, epsilon)\n",
    "    TDOA_images_ref.append((image1, image2, image3))\n",
    "    if(len(TDOA_images_ref) % 1000 == 0):\n",
    "      print(len(TDOA_images_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wZgxWIEFGmQ"
   },
   "source": [
    "### Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxZNExOg_KAD"
   },
   "outputs": [],
   "source": [
    "TDOA_images_cnn = TDOA_images_ref\n",
    "ylabels = ylabel_ref\n",
    "\n",
    "TDOA_images_test = TDOA_images_cnn[int(0.8*MC_N):]\n",
    "TDOA_image_val = TDOA_images_cnn[int(0.6*MC_N):int(0.8*MC_N)]\n",
    "TDOA_image_train = TDOA_images_cnn[:int(0.6*MC_N)]\n",
    "\n",
    "ylabels_test = ylabels[int(0.8*MC_N):]\n",
    "ylabels_val = ylabels[int(0.6*MC_N):int(0.8*MC_N)]\n",
    "ylabels_train = ylabels[:int(0.6*MC_N)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuK5Z6DXFMT6"
   },
   "source": [
    "### Make model structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn_Ttq6u8Fnu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_cnn():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(CNN1_outchannel, (CNN1_kernal, CNN1_kernal), activation=layers.LeakyReLU(alpha=0.01), strides=CNN1_stride, \n",
    "                            input_shape= (TDOA_sample_image.shape[0],TDOA_sample_image.shape[1], CNN1_inputchannel) ,kernel_initializer='he_normal'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(Pool_kernal,Pool_kernal), strides= (Pool_stride, Pool_stride), padding = \"SAME\"  ) )\n",
    "    model.add(layers.Conv2D(CNN2_outchannel, (CNN2_kernal, CNN2_kernal),  activation=layers.LeakyReLU(alpha=0.01), strides=CNN2_stride ,kernel_initializer='he_normal'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(Pool_kernal,Pool_kernal), strides=  (Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "    model.add(layers.Conv2D(CNN3_outchannel, (CNN3_kernal, CNN3_kernal), activation=layers.LeakyReLU(alpha=0.01), strides=CNN3_stride ,kernel_initializer='he_normal'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(Pool_kernal,Pool_kernal), strides=  (Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    model.add(layers.Conv2D(CNN3_outchannel, (CNN3_kernal, CNN3_kernal), activation=layers.LeakyReLU(alpha=0.01), strides=CNN3_stride ,kernel_initializer='he_normal')) \n",
    "    model.add(layers.BatchNormalization()) \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation=None))\n",
    "    return model\n",
    "\n",
    "model = create_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NS-j5cH_LsA",
    "outputId": "6fb26c74-feda-4183-ec4c-01409e728603"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"weight/cnn/cp-{epoch:02d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = True, save_freq='epoch',  monitor='val_loss', verbose=1, mode=\"min\")\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', \n",
    "                              patience=5)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_mse', factor=0.8, verbose=1, mode=\"min\",\n",
    "                              patience=4, min_lr=0.0001)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1 * 1e-4),\n",
    "        loss='MSE',\n",
    "        metrics=['mse'])\n",
    "\n",
    "\n",
    "history = model.fit(np.array(TDOA_image_train).swapaxes(1,3), np.array(ylabels_train),\n",
    "                    epochs=num_epochs, batch_size=batch_size,verbose=1,\n",
    "                    validation_data=(np.array(TDOA_image_val).swapaxes(1,3), np.array(ylabels_val)),\n",
    "                     callbacks= [ earlystopping, reduce_lr, cp_callback])\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "d3ENPh8GAr3g",
    "outputId": "38b69db1-ce3c-4b2b-d42f-2f95c7e16e10"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "hist = history\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.plot(hist.history[\"loss\"], label = 'loss', marker='o')\n",
    "ax.plot(hist.history[\"val_loss\"], label = 'val_loss', marker='o')\n",
    "ax.legend()\n",
    "\n",
    "plt.title('CNN', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_history = hist.history[\"val_loss\"]\n",
    "max_point = val_loss_history.index(min(val_loss_history))\n",
    "\n",
    "model = create_cnn()\n",
    "model.compile(optimizer=Adam(learning_rate=1 * 1e-3),\n",
    "        loss='MSE',\n",
    "        metrics=['mse'])\n",
    "\n",
    "if max_point > 9:\n",
    "    model.load_weights(\n",
    "        \"weight/cnn/cp-\" + str(max_point+1) + \".ckpt\"\n",
    "    )\n",
    "else:\n",
    "    model.load_weights(\n",
    "        \"weight/cnn/cp-0\" + str(max_point+1) + \".ckpt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XI7uaWXeA1uV",
    "outputId": "735361d0-d494-4623-b5b1-5159e6900353"
   },
   "outputs": [],
   "source": [
    "predict_X_Hats = model.predict(np.array(TDOA_images_test).swapaxes(1,3))\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*world_size_x - np.array(ylabels_test)*world_size_x), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vb90DJsEaJkU"
   },
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO_q5jfKJgpA"
   },
   "source": [
    "\n",
    "  <img src='https://drive.google.com/uc?id=1TRRt2YHofQiDwstmSEIkLiWsmK2EKut5' width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHI0pSSEFPgi"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPagPq8AYpJZ"
   },
   "source": [
    "### 1. Grid size really matters. \n",
    "\n",
    "The smaller the grid size, the more data for model input become more complex but the result is better. (Tradeoff between computational time and error)\n",
    "\n",
    "< For grid_size = 1>\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TOz4y_V3nlOJZOyQVXCMRR7hfQhtSV-J' width=\"350\">\n",
    "\n",
    "< For grid_size = 0.5>\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TPEyYMEnw373MX247bg8uNxfVx038zNt' width=\"300\">\n",
    "\n",
    "\n",
    "### 2. Probability_gap and Epsilon must change relation to Grid size \n",
    "\n",
    "If the value grid size changes, the hyperparameters must be modified accordingly.In the process, the following facts were additionally discovered.\n",
    "\n",
    "\n",
    "\n",
    "*   The probability gap is not unconditionally good because it is large unlike the grid size.\n",
    "*   Most of the epsilon values showed good performance when values slightly smaller than (gridsize / probability_gap * 2).\n",
    "\n",
    "\n",
    "\n",
    "### 3. Comparing with reference paper [Nitsoo et al., 2018]\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1TPrf8VJXT4FzvFmAspuF8G5nIhLNfFix' width=\"600\">\n",
    "\n",
    "\n",
    "  <img src='https://drive.google.com/uc?id=1TQu6JWMw4gs6nN97aX13zp1oFusLRFN_' width=\"600\">\n",
    "\n",
    "  In our reference paper, coverage area is 13m x 20m, \n",
    "  \\\n",
    "   MAE is 0.3m~0.8m by various algorithms.\n",
    "\n",
    "  Our coverage area is 25m x 25m and MAE for CNN model is 0.4m\n",
    "  \\\n",
    "  If we consider large coverage area compare and error rate, our result is quite **meaningful** even considering that the environment is a little different.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi94XIOB5K3q"
   },
   "source": [
    "\n",
    "## 3. FCNN (Fully connected Neural Network) Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LLIxw-t2o2V",
    "outputId": "82a94f82-93a8-42ff-e7af-f18fe73b2749"
   },
   "outputs": [],
   "source": [
    "# Do not modify this block\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_fcnn():\n",
    "    model2 = models.Sequential()\n",
    "    model2.add(layers.Dense(32, activation='relu', input_shape=(3,)))\n",
    "    model2.add(layers.Dropout(0.4))\n",
    "    model2.add(layers.Dense(16, activation='relu'))\n",
    "    model2.add(layers.Dense(8, activation='relu'))\n",
    "    model2.add(layers.Dense(2))\n",
    "    model2.compile(optimizer=Adam(learning_rate=1 * 1e-3), loss='mse', metrics=['mse'])\n",
    "    return model2\n",
    "\n",
    "checkpoint_path = \"weight/fcnn/cp-{epoch:02d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = True, save_freq='epoch',  monitor='val_loss', verbose=1, mode=\"min\")\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', \n",
    "                              patience=5)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_mse', factor=0.8, verbose=1, mode=\"min\",\n",
    "                              patience=4, min_lr=0.0001)\n",
    "\n",
    "model2 = create_fcnn()\n",
    "\n",
    "\n",
    "history = model2.fit(train_TDOAs[:int(0.75*MC_N*0.8)], \n",
    "                      train_X_Hats[:int(0.75*MC_N*0.8)],\n",
    "                      epochs=num_epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      callbacks= [earlystopping, reduce_lr,cp_callback],\n",
    "                      validation_data = (train_TDOAs[int(0.75*MC_N*0.8):], train_X_Hats[int(0.75*MC_N*0.8):]),\n",
    "                      verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model2, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "kFoQ-m0l2rA1",
    "outputId": "842069f6-7b8b-45be-be0e-f24bb5690a72"
   },
   "outputs": [],
   "source": [
    "hist = history\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.plot(hist.history[\"loss\"], label = 'loss', marker='o')\n",
    "ax.plot(hist.history[\"val_loss\"], label = 'val_loss', marker='o')\n",
    "ax.legend()\n",
    "\n",
    "plt.title('FCNNs', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-8HBjlw2tL_",
    "outputId": "fd65eadb-8372-4aab-a5f6-9eee511b5b3c"
   },
   "outputs": [],
   "source": [
    "val_loss_history = hist.history[\"val_loss\"]\n",
    "max_point3 = val_loss_history.index(min(val_loss_history))\n",
    "\n",
    "model2 = create_fcnn()\n",
    "\n",
    "if max_point3 > 8:\n",
    "    model2.load_weights(\n",
    "        \"weight/fcnn/cp-\" + str(max_point3+1) + \".ckpt\"\n",
    "    )\n",
    "else:\n",
    "    model2.load_weights(\n",
    "        \"weight/fcnn/cp-0\" + str(max_point3+1) + \".ckpt\"\n",
    "    )\n",
    "\n",
    "predict_X_Hats = model2.predict(test_TDOAs)\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*world_size_x - test_X_Hats*world_size_x), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yng1gkjBVlNB",
    "outputId": "66139d00-7704-40c6-c9c3-e08719d6a7af"
   },
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(X, y, seqLength):\n",
    "    xdata = []\n",
    "    ydata = [] \n",
    "    for i in range(0, len(X)-seqLength):\n",
    "        tx = X[i:i+seqLength,:]\n",
    "        ty = y[i+seqLength,[-1]]\n",
    "        xdata.append(tx)\n",
    "        ydata.append(ty)\n",
    "    return np.array(xdata), np.array(ydata)\n",
    "\n",
    "seqLength=4\n",
    "trainX_lstm, trainY_lstm=buildDataSet(train_TDOAs, train_X_Hats, seqLength)\n",
    "testX_lstm, testY_lstm=buildDataSet(test_TDOAs, test_X_Hats, seqLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def create_lstm():\n",
    "    model_lstm = models.Sequential()\n",
    "    model_lstm.add(LSTM(8,input_shape=(seqLength, 3),return_sequences=False)) \n",
    "    model_lstm.add(layers.Dropout(0.5)) \n",
    "    model_lstm.add(layers.Dense(2)) \n",
    "    model_lstm.compile(optimizer=Adam(learning_rate=1.0 * 1e-3), loss='mse', metrics=['mse'])\n",
    "    return model_lstm\n",
    "\n",
    "\n",
    "model_lstm =  create_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weight/lstm/cp-{epoch:02d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = True, save_freq='epoch',  monitor='val_loss', verbose=1, mode=\"min\")\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=5)\n",
    "                              \n",
    "history = model_lstm.fit(trainX_lstm[:int(0.75*MC_N*0.8)], \n",
    "                      trainY_lstm[:int(0.75*MC_N*0.8)],\n",
    "                      epochs=num_epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=1,\n",
    "                      validation_data= (trainX_lstm[int(0.75*MC_N*0.8):], trainY_lstm[int(0.75*MC_N*0.8):]),\n",
    "                      callbacks= [earlystopping, reduce_lr,cp_callback] \n",
    "                      )\n",
    "                      \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_lstm, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.plot(hist.history[\"loss\"], label = 'loss', marker='o')\n",
    "ax.plot(hist.history[\"val_loss\"], label = 'val_loss', marker='o')\n",
    "ax.legend()\n",
    "\n",
    "plt.title('LSTM', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_history = hist.history[\"val_loss\"]\n",
    "max_point4 = val_loss_history.index(min(val_loss_history))\n",
    "\n",
    "model_lstm = create_lstm()\n",
    "\n",
    "if max_point4 > 8:\n",
    "    model_lstm.load_weights(\n",
    "        \"weight/lstm/cp-\" + str(max_point4+1) + \".ckpt\"\n",
    "    )\n",
    "else:\n",
    "    model_lstm.load_weights(\n",
    "        \"weight/lstm/cp-0\" + str(max_point4+1) + \".ckpt\"\n",
    "    )\n",
    "\n",
    "\n",
    "predict_X_Hats = model_lstm.predict(testX_lstm)\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*world_size_x - testY_lstm*world_size_x), axis = 1))\n",
    "\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_time_series = 4\n",
    "\n",
    "TDOA_images_ref_temp = np.array(TDOA_images_ref)\n",
    "\n",
    "for i in range(lstm_time_series):\n",
    "    globals()['TDOA_imgaes_lstm{}'.format(i)] = TDOA_images_ref_temp[i:int(MC_N-lstm_time_series+i+1)]\n",
    "\n",
    "TDOA_images_lstm = np.stack(  [TDOA_imgaes_lstm0 , TDOA_imgaes_lstm1,TDOA_imgaes_lstm2,TDOA_imgaes_lstm3] ,axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabels = np.array(ylabels)\n",
    "\n",
    "for i in range(lstm_time_series):\n",
    "    globals()['ylabels_lstm{}'.format(i)] = ylabels[i:int(MC_N-lstm_time_series+i+1)]\n",
    "\n",
    "ylabels_lstm = np.stack(  [ylabels_lstm0, ylabels_lstm1, ylabels_lstm2, ylabels_lstm3] ,axis=1 )\n",
    "\n",
    "ylabels_lstm = ylabels[lstm_time_series-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDOA_images_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabels_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TDOA_images_test_lstm = TDOA_images_lstm[int(0.8*MC_N):]\n",
    "TDOA_image_val_lstm = TDOA_images_lstm[int(0.6*MC_N):int(0.8*MC_N)]\n",
    "TDOA_image_train_lstm = TDOA_images_lstm[:int(0.6*MC_N)]\n",
    "\n",
    "\n",
    "\n",
    "ylabels_test_lstm = ylabels_lstm[int(0.8*MC_N):]\n",
    "ylabels_val_lstm = ylabels_lstm[int(0.6*MC_N):int(0.8*MC_N)]\n",
    "ylabels_train_lstm = ylabels_lstm[:int(0.6*MC_N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_lstm():\n",
    "    seq = keras.Sequential()\n",
    "    seq.add(layers.ConvLSTM2D(CNN1_outchannel, (CNN1_kernal, CNN1_kernal),\n",
    "                            input_shape= (4, TDOA_sample_image.shape[0],TDOA_sample_image.shape[1], CNN1_inputchannel ) ,return_sequences=True))\n",
    "    seq.add(layers.MaxPool3D(pool_size=(Pool_kernal,Pool_kernal,Pool_kernal), strides= (1,Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    seq.add(layers.ConvLSTM2D(CNN2_outchannel, (CNN2_kernal, CNN2_kernal),return_sequences=True))\n",
    "    seq.add(layers.MaxPool3D(pool_size=(Pool_kernal,Pool_kernal,Pool_kernal), strides=  (1,Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    seq.add(layers.Dropout(0.6))\n",
    "    seq.add(layers.ConvLSTM2D(CNN3_outchannel, (CNN3_kernal, CNN3_kernal),return_sequences=True))\n",
    "    seq.add(layers.MaxPool3D(pool_size=(Pool_kernal,Pool_kernal,Pool_kernal), strides=  (1,Pool_stride, Pool_stride), padding = \"SAME\"))\n",
    "    seq.add(layers.ConvLSTM2D(CNN3_outchannel, (CNN3_kernal, CNN3_kernal),return_sequences=False))\n",
    "    seq.add(layers.BatchNormalization()) \n",
    "    seq.add(layers.Flatten())\n",
    "    seq.add(layers.Dense(128, activation='relu'))\n",
    "    seq.add(layers.Dropout(0.5))\n",
    "    seq.add(layers.Dense(32, activation='relu'))\n",
    "    seq.add(layers.Dense(2, activation=None))\n",
    "    return seq\n",
    "\n",
    "\n",
    "\n",
    "seq = create_conv_lstm()\n",
    "plot_model(seq, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.compile(optimizer=Adam(learning_rate=1.0 * 1e-3),\n",
    "        loss='mse',\n",
    "        metrics=['mse'])\n",
    "\n",
    "checkpoint_path = \"weight/conv_cnn/cp-{epoch:02d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = True, save_freq='epoch',  monitor='val_mse', verbose=1, mode=\"min\")\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_mse', \n",
    "                              patience=8) \n",
    "\n",
    "\n",
    "history = seq.fit(TDOA_image_train_lstm.swapaxes(2,4), ylabels_train_lstm,\n",
    "                    epochs=num_epochs, batch_size=batch_size,verbose=1,validation_data=(TDOA_image_val_lstm.swapaxes(2,4), ylabels_val_lstm),\n",
    "                     callbacks= [earlystopping, reduce_lr, cp_callback])\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.plot(hist.history[\"loss\"], label = 'loss', marker='o')\n",
    "ax.plot(hist.history[\"val_loss\"], label = 'val_loss', marker='o')\n",
    "ax.legend()\n",
    "\n",
    "plt.title('Conv-lstm', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_history = hist.history[\"val_loss\"]\n",
    "max_point2 = val_loss_history.index(min(val_loss_history))\n",
    "\n",
    "seq = create_conv_lstm()\n",
    "seq.compile(optimizer=Adam(learning_rate=1 * 1e-3),\n",
    "        loss='MSE',\n",
    "        metrics=['mse'])\n",
    "\n",
    "if max_point2 > 8:\n",
    "    seq.load_weights(\n",
    "        \"weight/conv_cnn/cp-\" + str(max_point2+1) + \".ckpt\"\n",
    "    )\n",
    "else:\n",
    "    seq.load_weights(\n",
    "        \"weight/conv_cnn/cp-0\" + str(max_point2+1) + \".ckpt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_X_Hats = seq.predict(TDOA_images_test_lstm.swapaxes(2,4))\n",
    "\n",
    "distance_gap = np.sqrt(np.sum(np.square(predict_X_Hats*world_size_x -ylabels_test_lstm*world_size_x), axis = 1))\n",
    "mean_distance_gap = np.mean(distance_gap)\n",
    "print('평균 오차 거리 : ' , np.round(mean_distance_gap,4) , '미터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distance_gap, bins=20)\n",
    "plt.xlim(0,10)\n",
    "plt.xticks(range(0,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_point3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_point2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TDOA_present_[3].ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "5a905c007ff2d38bb2c7b3a29a7607fb69ad0b0424e092736524db498399bd8a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('position31')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
